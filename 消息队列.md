# 消息队列基本内容

## [消息队列是什么？](https://www.zhihu.com/question/54152397/answer/1802083263)

消息队列解决的最核心的问题：系统解耦

![](https://pic3.zhimg.com/80/v2-b0b81fcf533970cd71d23a85ec266e5b_1440w.jpg?source=1940ef5c)



举一个实际例子，比如说电商业务中最常见的「订单支付」场景：在订单支付成功后，需要更新订单状态、更新用户积分、通知商家有新订单、更新推荐系统中的用户画像等等。

引入 MQ 后，订单支付现在只需要关注它最重要的流程：更新订单状态即可。其他不重要的事情全部交给 MQ 来通知。这便是 MQ 解决的最核心的问题：系统解耦。

改造前订单系统依赖 3 个外部系统，改造后仅仅依赖 MQ，而且后续业务再扩展（比如：营销系统打算针对支付用户奖励优惠券），也不涉及订单系统的修改，从而保证了核心流程的稳定性，降低了维护成本。

这个改造还带来了另外一个好处：因为 MQ 的引入，更新用户积分、通知商家、更新用户画像这些步骤全部变成了异步执行，能减少订单支付的整体耗时，提升订单系统的吞吐量。这便是 MQ 的另一个典型应用场景：异步通信。

除此以外，由于队列能转储消息，对于超出系统承载能力的场景，可以用 MQ 作为 “漏斗” 进行限流保护，即所谓的流量削峰。

我们还可以利用队列本身的顺序性，来满足消息必须按顺序投递的场景；利用队列 + 定时任务来实现消息的延时消费。

## [为什么用消息队列？](https://www.zhihu.com/question/54152397/answer/923992679)

### 异步

#### 为什么不顺序执行？

流程长，相应时间慢。

#### 为什么使用消息队列？

你下单了，你就把你**支付成功的消息告诉别的系统**，他们收到了去处理就好了，你只用走完自己的流程，把自己的消息发出去，那后面要接入什么系统简单，直接订阅你发送的支付成功消息，你支付成功了我**监听就好了**。

![img](https://pic2.zhimg.com/50/v2-ee2ed0c6889e4f1f157010745dd0f162_720w.jpg?source=1940ef5c)

### 削峰

平时流量很低，但是你要做秒杀活动00 ：00的时候流量疯狂怼进来，你的**服务器**，**Redis**，**MySQL**各自的承受能力都不一样，你直接**全部流量照单全收**肯定有问题啊，直接就打挂了。

简单，把请求放到队列里面，然后至于每秒消费多少请求，就看自己的**服务器处理能力**，你能处理5000QPS你就消费这么多，可能会比正常的慢一点，但是**不至于打挂服务器**，等流量高峰下去了，你的服务也就没压力了。

### 解耦

#### 为什么不用线程？

既然面试官这么问了，我就说一下为啥我们不能用线程去做，因为用线程去做，你是不是要写代码？

你一个订单流程，你扣积分，扣优惠券，发短信，扣库存。。。等等这么多业务要调用这么多的接口，**每次加一个你要调用一个接口然后还要重新发布系统**，写一次两次还好，写多了你就说：老子不干了！

而且真的全部都写在一起的话，不单单是耦合这一个问题，你出问题排查也麻烦，流程里面随便一个地方出问题搞不好会影响到其他的点，小伙伴说我每个流程都**try catch**不就行了，相信我别这么做，这样的代码就像个**定时炸弹** ，你不知道什么时候爆炸，平时不炸偏偏在你做活动的时候炸，你就领个**P0故障**收拾书包**提前回家过年**吧。

Tip：P0—PN 是互联网大厂经常用来判定事故等级的机制，P0是最高等级了。

## 消息队列缺点

### 系统复杂性

本来蛮简单的一个系统，我代码随便写都没事，现在你凭空接入一个中间件在那，我是不是要考虑去维护他，而且使用的过程中是不是要考虑各种问题，比如**消息重复消费**、**消息丢失**、**消息的顺序消费**等等，反正用了之后就是贼烦。

### 数据一致性

这个其实是分布式服务本身就存在的一个问题，**不仅仅是消息队列的问题**，但是放在这里说是因为用了消息队列这个问题会暴露得比较严重一点。

就像我开头说的，你下单的服务自己保证自己的逻辑成功处理了，你成功发了消息，但是优惠券系统，积分系统等等这么多系统，**他们成功还是失败你就不管了？**

**所有的服务都成功才能算这一次下单是成功的**，那怎么才能保证数据一致性呢？

**分布式事务**：把下单，优惠券，积分。。。都放在一个事务里面一样，要成功一起成功，要失败一起失败。

### 可用性

你搞个系统本身没啥问题，你现在突然接入一个中间件在那放着，万一挂了怎么办？我下个单**MQ挂了**，优惠券不扣了，积分不减了，这不是杀一个程序员能搞定的吧，感觉得杀一片。

# Redis实现消息队列

[Redis怎么做消息队列？](https://www.zhihu.com/question/20795043)

主要内容：redis实现消息队列的三种方式以及优缺点

## List队列

- 不支持重复消费
  - 消费者拉取消息后，这条消息就从 List 中删除了，无法被其它消费者再次消费，即不支持多个消费者消费同一批数据
- 消息丢失
  - 消费者拉取到消息后，如果发生异常宕机，那这条消息就丢失了

## 发布/订阅模型：Pub/Sub

- 支持发布/订阅，支持多组生产者消费者处理消息
- 消费者下线，消息会丢失
- 不支持数据持久化，redis宕机，数据也会丢失
- 消息堆积，缓冲区移除，消费者会被强制踢下线，数据也会丢失

## Stream

- stream支持阻塞式拉取消息
  - 读取消息时，只需要增加BLOCK参数即可
- stream支持发布订阅模式
  - XGROUP：创建消费者组
  - XREADGROUP：在指定消费组下，开启消费者拉取消息
- 消息处理异常时，stream可以保证消息不丢失，重新消费
  - 当一组消费者处理完消息消息后，需要执行XACK命令告知redis，这是redis就会把这条消息标记为“处理完成”
- 数据持久化
  - 每个写操作，也都会写入到RDB和AOF中。
- 指定队列长度，防止队列挤压
  - 在发布消息时，可以指定队列的最大长度，防止队列挤压导致内存爆炸
  - 当队列长度超过上限后，就消息会被删除，只保留固定的长度的新消息。

## Redis实现消息队列中的问题

- redis本身无法保证严格的数据完整性，redis本身可能丢失数据。
  - AOF 持久化配置为每秒写盘，但这个写盘过程是异步的，Redis 宕机时会存在数据丢失的可能
  - 主从复制也是异步的，主从切换时，也存在丢失数据的可能（从库还未同步完成主库发来的数据，就被提成主库）
- 面对消息积压，redis内存资源紧张
  - 因为 Redis 的数据都存储在内存中，这就意味着一旦发生消息积压，则会导致 Redis 的内存持续增长，如果超过机器内存上限，就会面临被 OOM 的风险。





#### 